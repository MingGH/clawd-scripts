#!/usr/bin/env python3
import boto3
from botocore.config import Config
import os
from datetime import datetime

# Cloudflare R2 é…ç½®
R2_CONFIG = {
    "bucket_name": "openbot-upload",
    "endpoint_url": "https://8034b6f645143efa728dad5b5df39e7bd.r2.cloudflarestorage.com",
    "access_key_id": "77934f3344f603fd8221404a62b51b91",
    "secret_access_key": "0d3732d1811748f7c4b69f4fa0476f5aea0f31b2aef93016c8c1c569bc8ee7af",
    "region": "auto",  # Cloudflare R2 ä½¿ç”¨ auto åŒºåŸŸ
    "public_domain": "openbotfile.996.ninja"
}

# è¦ä¸Šä¼ çš„æ–‡ä»¶
FILES_TO_UPLOAD = [
    "/tmp/uptime_kuma_analysis.png",
    "/tmp/uptime_kuma_logged_in.png",
    "/tmp/uptime_kuma_screenshot.png"
]

def create_r2_client():
    """åˆ›å»ºR2 S3å®¢æˆ·ç«¯"""
    try:
        # é…ç½®S3å®¢æˆ·ç«¯
        s3_config = Config(
            region_name=R2_CONFIG["region"],
            s3={'addressing_style': 'virtual'},
            signature_version='s3v4'
        )
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        s3_client = boto3.client(
            's3',
            endpoint_url=R2_CONFIG["endpoint_url"],
            aws_access_key_id=R2_CONFIG["access_key_id"],
            aws_secret_access_key=R2_CONFIG["secret_access_key"],
            config=s3_config
        )
        
        print("âœ… R2 S3å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        return s3_client
    except Exception as e:
        print(f"âŒ åˆ›å»ºR2å®¢æˆ·ç«¯å¤±è´¥: {e}")
        return None

def check_bucket_exists(s3_client):
    """æ£€æŸ¥å­˜å‚¨æ¡¶æ˜¯å¦å­˜åœ¨"""
    try:
        s3_client.head_bucket(Bucket=R2_CONFIG["bucket_name"])
        print(f"âœ… å­˜å‚¨æ¡¶ '{R2_CONFIG['bucket_name']}' å­˜åœ¨")
        return True
    except Exception as e:
        print(f"âŒ å­˜å‚¨æ¡¶æ£€æŸ¥å¤±è´¥: {e}")
        return False

def upload_file(s3_client, file_path):
    """ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ°R2"""
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None
    
    # ç”Ÿæˆå¯¹è±¡é”®ï¼ˆä½¿ç”¨æ—¥æœŸæ—¶é—´æˆ³é¿å…å†²çªï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    file_name = os.path.basename(file_path)
    object_key = f"uptime-kuma/{timestamp}_{file_name}"
    
    try:
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_size = os.path.getsize(file_path)
        file_size_mb = file_size / (1024 * 1024)
        
        print(f"\nğŸ“¤ ä¸Šä¼ æ–‡ä»¶: {file_name}")
        print(f"   å¤§å°: {file_size_mb:.2f} MB")
        print(f"   å¯¹è±¡é”®: {object_key}")
        
        # ä¸Šä¼ æ–‡ä»¶
        with open(file_path, 'rb') as file_data:
            s3_client.put_object(
                Bucket=R2_CONFIG["bucket_name"],
                Key=object_key,
                Body=file_data,
                ContentType='image/png' if file_name.endswith('.png') else 'application/octet-stream'
            )
        
        # ç”Ÿæˆå…¬å¼€è®¿é—®URL
        public_url = f"https://{R2_CONFIG['public_domain']}/{object_key}"
        
        print(f"âœ… ä¸Šä¼ æˆåŠŸ!")
        print(f"ğŸ”— å…¬å¼€URL: {public_url}")
        
        return {
            "object_key": object_key,
            "public_url": public_url,
            "file_name": file_name,
            "file_size": file_size
        }
        
    except Exception as e:
        print(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
        return None

def list_bucket_contents(s3_client):
    """åˆ—å‡ºå­˜å‚¨æ¡¶å†…å®¹"""
    try:
        print(f"\nğŸ“‚ å­˜å‚¨æ¡¶ '{R2_CONFIG['bucket_name']}' å†…å®¹:")
        
        response = s3_client.list_objects_v2(Bucket=R2_CONFIG["bucket_name"])
        
        if 'Contents' in response:
            for obj in response['Contents']:
                size_kb = obj['Size'] / 1024
                last_modified = obj['LastModified'].strftime("%Y-%m-%d %H:%M:%S")
                print(f"  â€¢ {obj['Key']} ({size_kb:.1f} KB, {last_modified})")
        else:
            print("  (ç©ºå­˜å‚¨æ¡¶)")
            
    except Exception as e:
        print(f"âŒ åˆ—å‡ºå†…å®¹å¤±è´¥: {e}")

def main():
    print("=== Cloudflare R2 æ–‡ä»¶ä¸Šä¼ å·¥å…· ===\n")
    
    # åˆ›å»ºR2å®¢æˆ·ç«¯
    s3_client = create_r2_client()
    if not s3_client:
        return
    
    # æ£€æŸ¥å­˜å‚¨æ¡¶
    if not check_bucket_exists(s3_client):
        print("å°è¯•åˆ›å»ºå­˜å‚¨æ¡¶...")
        try:
            s3_client.create_bucket(Bucket=R2_CONFIG["bucket_name"])
            print("âœ… å­˜å‚¨æ¡¶åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"âŒ åˆ›å»ºå­˜å‚¨æ¡¶å¤±è´¥: {e}")
            return
    
    # ä¸Šä¼ æ–‡ä»¶
    uploaded_files = []
    for file_path in FILES_TO_UPLOAD:
        if os.path.exists(file_path):
            result = upload_file(s3_client, file_path)
            if result:
                uploaded_files.append(result)
        else:
            print(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶: {file_path}")
    
    # åˆ—å‡ºå­˜å‚¨æ¡¶å†…å®¹
    list_bucket_contents(s3_client)
    
    # è¾“å‡ºæ€»ç»“
    print(f"\n=== ä¸Šä¼ æ€»ç»“ ===")
    print(f"æ€»å…±å°è¯•ä¸Šä¼ : {len(FILES_TO_UPLOAD)} ä¸ªæ–‡ä»¶")
    print(f"æˆåŠŸä¸Šä¼ : {len(uploaded_files)} ä¸ªæ–‡ä»¶")
    
    if uploaded_files:
        print("\nğŸ“ ä¸Šä¼ çš„æ–‡ä»¶é“¾æ¥:")
        for file_info in uploaded_files:
            print(f"  â€¢ {file_info['file_name']}: {file_info['public_url']}")
    
    print(f"\nğŸŒ å…¬å¼€åŸŸå: https://{R2_CONFIG['public_domain']}/")
    print("ğŸ’¡ æç¤º: ä½ å¯ä»¥é€šè¿‡å…¬å¼€åŸŸåç›´æ¥è®¿é—®ä¸Šä¼ çš„æ–‡ä»¶")

if __name__ == "__main__":
    main()